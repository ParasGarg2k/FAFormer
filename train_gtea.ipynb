{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cair/miniconda3/envs/videomaev2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/cair/Dharmendra/FACT_actseg/src\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup environment, imports, paths\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import wandb\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "# 1) Set your project root folder here (whe\n",
    "# re utils/, models/, configs/ are)\n",
    "PROJECT_ROOT = \"FACT\"\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# 2) Import your modules with fixed absolute import paths (no leading dot)\n",
    "from utils.dataset import DataLoader, create_dataset\n",
    "from utils.evaluate import Checkpoint\n",
    "from home import get_project_base\n",
    "from configs.utils import cfg2flatdict, setup_cfg\n",
    "from utils.train_tools import resume_ckpt, compute_null_weight, save_results\n",
    "from models.loss import MatchCriterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration (replace with your actual config yaml files or dicts)\n",
    "\n",
    "# List of config yaml files relative to PROJECT_ROOT or absolute paths\n",
    "CONFIG_FILES = [\n",
    "    \"FACT/configs/gtea3.yaml\"\n",
    "]\n",
    "\n",
    "# Example override configs as a list (like --set in CLI)\n",
    "SET_CFGS = [\n",
    "    \"dataset\", \"gtea\",\n",
    "    \"split\", \"split2\",\n",
    "    \"aux.gpu\", \"0\",\n",
    "    \"batch_size\", \"1\",\n",
    "    \"epoch\", \"400\",\n",
    "    \"lr\", \"0.0001\",\n",
    "    \"optimizer\", \"Adam\",\n",
    "    \"aux.debug\", False,\n",
    "    \"aux.eval_every\", \"500\",\n",
    "    \"aux.print_every\", \"100\",\n",
    "    \"clip_grad_norm\", \"10.0\"\n",
    "    # no override for Loss.temporal_affinity_weight here!\n",
    "]\n",
    "\n",
    "\n",
    "# Setup config object\n",
    "cfg = setup_cfg(CONFIG_FILES, SET_CFGS)\n",
    "\n",
    "# Fix base directory to project root (optional, depends on your get_project_base implementation)\n",
    "BASE = PROJECT_ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d53b5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (SSLError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.5s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>log/gtea/split2/gtea/1/wandb/run-20250716_163344-sfcemhv6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT/runs/sfcemhv6' target=\"_blank\">azure-fog-10</a></strong> to <a href='https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT' target=\"_blank\">https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT/runs/sfcemhv6' target=\"_blank\">https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT/runs/sfcemhv6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 3: Initialize wandb (optional, you can disable if you want)\n",
    "\n",
    "try:\n",
    "    run = wandb.init(\n",
    "        project=cfg.aux.wandb_project if hasattr(cfg.aux, 'wandb_project') else \"default_project\",\n",
    "        entity=cfg.aux.wandb_user if hasattr(cfg.aux, 'wandb_user') else None,\n",
    "        dir=cfg.aux.logdir if hasattr(cfg.aux, 'logdir') else \"./wandb_logs\",\n",
    "        group=cfg.aux.exp if hasattr(cfg.aux, 'exp') else None,\n",
    "        resume=\"allow\",\n",
    "        config=cfg2flatdict(cfg),\n",
    "        reinit=True,\n",
    "        save_code=False,\n",
    "        mode=\"offline\" if cfg.aux.debug else \"online\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"WARNING: Failed to initialize wandb.\")\n",
    "    run = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6357820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logs in: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Setup directories & save config\n",
    "\n",
    "logdir = os.path.join(BASE, cfg.aux.logdir if hasattr(cfg.aux, 'logdir') else \"logs\")\n",
    "ckptdir = os.path.join(logdir, 'ckpts')\n",
    "savedir = os.path.join(logdir, 'saves')\n",
    "\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "os.makedirs(ckptdir, exist_ok=True)\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "print(\"Saving logs in:\", logdir)\n",
    "\n",
    "# Save config dict as json for reference\n",
    "argSaveFile = os.path.join(logdir, 'args.json')\n",
    "with open(argSaveFile, 'w') as f:\n",
    "    json.dump(cfg, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01718741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Feature from /home/cair/Dharmendra/data_i3d/gtea/features/\n",
      "Loading Label from /home/cair/Dharmendra/data_i3d/gtea/groundTruth\n",
      "Train dataset: < Dataset 21 videos, 2048 feat-size, 11 classes >\n",
      "Test dataset: < Dataset 7 videos, 2048 feat-size, 11 classes >\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load datasets\n",
    "\n",
    "dataset, test_dataset = create_dataset(cfg)\n",
    "\n",
    "if not cfg.aux.debug:\n",
    "    trainloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "else:\n",
    "    trainloader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "testloader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False)\n",
    "\n",
    "print(\"Train dataset:\", dataset)\n",
    "print(\"Test dataset:\", test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cbde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resume, Train from Scratch\n",
      "FACT(\n",
      "  (frame_pe): PositionalEncoding(EMPTY)\n",
      "  (channel_masking_dropout): Dropout2d(p=0.5, inplace=False)\n",
      "  (block_list): ModuleList(\n",
      "    (0): InputBlock(\n",
      "      f:MSTCN(h:2048->128x10->512, d=2, ng=1, dropout=0.2, in_map=True),\n",
      "      a:SCADecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): SCALayer( adim:128, fdim:512, head:8, ffdim:512, dropout:(0.2, 0.2), svpos:False, cvpos:False )\n",
      "        (1): SCALayer( adim:128, fdim:512, head:8, ffdim:512, dropout:(0.2, 0.2), svpos:False, cvpos:False )\n",
      "        (2): SCALayer( adim:128, fdim:512, head:8, ffdim:512, dropout:(0.2, 0.2), svpos:False, cvpos:False )\n",
      "        (3): SCALayer( adim:128, fdim:512, head:8, ffdim:512, dropout:(0.2, 0.2), svpos:False, cvpos:False )\n",
      "        (4): SCALayer( adim:128, fdim:512, head:8, ffdim:512, dropout:(0.2, 0.2), svpos:False, cvpos:False )\n",
      "        (5): SCALayer( adim:128, fdim:512, head:8, ffdim:512, dropout:(0.2, 0.2), svpos:False, cvpos:False )\n",
      "      )\n",
      "      (out_linear): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    ),\n",
      "      a2f:None,\n",
      "      f2a:None\n",
      "    )\n",
      "    (1): UpdateBlock(\n",
      "      f:MSTCN(h:128->128x10->512, d=2, ng=1, dropout=0.2, in_map=False),\n",
      "      a:SADecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): SALayer( q(128)xkv(128)->128, head:8, ffdim:512, dropout:(0.2, 0.2), vpos:False )\n",
      "      )\n",
      "      (out_linear): Linear(in_features=128, out_features=512, bias=True)\n",
      "    ),\n",
      "      a2f:X2Y_map(\n",
      "      (X_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (X_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_W): Linear(in_features=1024, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    ),\n",
      "      f2a:X2Y_map(\n",
      "      (X_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (X_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_W): Linear(in_features=1024, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    )\n",
      "    (2): UpdateBlockTDU(\n",
      "      f:MSTCN(h:128->128x10->512, d=2, ng=1, dropout=0.2, in_map=False),\n",
      "      a:SADecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): SALayer( q(128)xkv(128)->128, head:8, ffdim:512, dropout:(0.2, 0.2), vpos:False )\n",
      "      )\n",
      "      (out_linear): Linear(in_features=128, out_features=512, bias=True)\n",
      "    ),\n",
      "      a2f:X2Y_map(\n",
      "      (X_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (X_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_W): Linear(in_features=1024, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    ),\n",
      "      f2a:X2Y_map(\n",
      "      (X_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (X_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (Y_W): Linear(in_features=1024, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create model and loss\n",
    "\n",
    "\n",
    "from models_faformer.fact import FACT\n",
    "net = FACT(cfg, dataset.input_dimension, dataset.nclasses)\n",
    "\n",
    "# Compute null class weight if needed\n",
    "if cfg.Loss.nullw == -1:\n",
    "    compute_null_weight(cfg, dataset)\n",
    "\n",
    "net.mcriterion = MatchCriterion(cfg, dataset.nclasses, dataset.bg_class)\n",
    "\n",
    "# Load checkpoint if exists\n",
    "global_step, ckpt_file = resume_ckpt(cfg, logdir)\n",
    "if ckpt_file is not None:\n",
    "    ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n",
    "    # Remove positional encodings if they exist in checkpoint (optional)\n",
    "    if 'frame_pe.pe' in ckpt: del ckpt['frame_pe.pe']\n",
    "    if 'action_pe.pe' in ckpt: del ckpt['action_pe.pe']\n",
    "    net.load_state_dict(ckpt, strict=False)\n",
    "\n",
    "net.cuda()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487eca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Setup optimizer\n",
    "\n",
    "if cfg.optimizer.lower() == 'sgd':\n",
    "    optimizer = optim.SGD(net.parameters(),\n",
    "                          lr=cfg.lr, momentum=cfg.momentum, weight_decay=cfg.weight_decay)\n",
    "elif cfg.optimizer.lower() == 'adam':\n",
    "    optimizer = optim.Adam(net.parameters(),\n",
    "                           lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "else:\n",
    "    raise NotImplementedError(f\"Optimizer {cfg.optimizer} not implemented.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2cf51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Evaluation function\n",
    "\n",
    "def evaluate(global_step, net, testloader, run, savedir):\n",
    "    print(\"TESTING\" + \"~\"*10)\n",
    "\n",
    "    ckpt = Checkpoint(global_step+1, bg_class=([] if net.cfg.eval_bg else testloader.dataset.bg_class))\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (vnames, seq_list, train_label_list, eval_label_list) in enumerate(testloader):\n",
    "\n",
    "            seq_list = [ s.cuda() for s in seq_list ]\n",
    "            train_label_list = [ s.cuda() for s in train_label_list ]\n",
    "            video_saves = net(seq_list, train_label_list)\n",
    "            save_results(ckpt, vnames, eval_label_list, video_saves)\n",
    "\n",
    "    net.train()\n",
    "    ckpt.compute_metrics()\n",
    "\n",
    "    log_dict = {}\n",
    "    string = \"\"\n",
    "    for k, v in ckpt.metrics.items():\n",
    "        string += \"%s:%.3f, \" % (k, v)\n",
    "        log_dict[f'test-metric/{k}'] = v\n",
    "    print(string + '\\n')\n",
    "\n",
    "    if run is not None:\n",
    "        run.log(log_dict, step=global_step+1)\n",
    "\n",
    "    fname = \"%d.gz\" % (global_step+1)\n",
    "    ckpt.save(os.path.join(savedir, fname))\n",
    "\n",
    "    return ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b60d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training from Epoch 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cair/miniconda3/envs/videomaev2/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter100, loss:9.7122, \n",
      "         AccB:14.5852, Acc:14.5852, F1@0.10:2.8458, F1@0.25:0.7760, F1@0.50:0.7760, \n",
      "Iter200, loss:8.2323, \n",
      "         AccB:29.2961, Acc:29.2961, F1@0.10:29.9819, F1@0.25:20.6344, F1@0.50:9.6997, \n",
      "Iter300, loss:6.9311, \n",
      "         AccB:41.8887, Acc:41.8887, F1@0.10:49.3146, F1@0.25:38.7210, F1@0.50:25.0224, \n",
      "Iter400, loss:6.2245, \n",
      "         AccB:52.1291, Acc:52.1291, F1@0.10:53.8963, F1@0.25:46.7601, F1@0.50:34.7413, \n",
      "Iter500, loss:5.7071, \n",
      "         AccB:61.4901, Acc:61.4901, F1@0.10:65.0576, F1@0.25:61.1255, F1@0.50:45.7547, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:58.164, AccB:56.523, Acc:65.685, F1@0.10:68.421, F1@0.25:62.280, F1@0.50:40.350, \n",
      "\n",
      "✅ Saved Best Model: F1@0.50 = 40.3504\n",
      "   ➤ .net format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.net\n",
      "   ➤ .pth format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.pth\n",
      "Iter600, loss:5.2168, \n",
      "         AccB:67.0262, Acc:67.0262, F1@0.10:67.1953, F1@0.25:62.9625, F1@0.50:53.2623, \n",
      "Iter700, loss:4.9951, \n",
      "         AccB:73.9138, Acc:73.9138, F1@0.10:72.1610, F1@0.25:69.4697, F1@0.50:58.8725, \n",
      "Iter800, loss:4.7872, \n",
      "         AccB:74.1564, Acc:74.1564, F1@0.10:74.8503, F1@0.25:71.0993, F1@0.50:59.8461, \n",
      "Iter900, loss:4.3660, \n",
      "         AccB:81.2779, Acc:81.2779, F1@0.10:80.9678, F1@0.25:78.1297, F1@0.50:68.6139, \n",
      "Iter1000, loss:4.1571, \n",
      "          AccB:79.0903, Acc:79.0903, F1@0.10:81.1565, F1@0.25:79.5036, F1@0.50:69.0904, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:72.717, AccB:69.558, Acc:71.417, F1@0.10:76.987, F1@0.25:73.640, F1@0.50:60.251, \n",
      "\n",
      "✅ Saved Best Model: F1@0.50 = 60.2505\n",
      "   ➤ .net format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.net\n",
      "   ➤ .pth format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.pth\n",
      "Iter1100, loss:3.9707, \n",
      "          AccB:84.0546, Acc:84.0546, F1@0.10:82.2655, F1@0.25:80.2951, F1@0.50:71.0997, \n",
      "Iter1200, loss:3.8047, \n",
      "          AccB:81.6158, Acc:81.6158, F1@0.10:84.2013, F1@0.25:80.8928, F1@0.50:71.2981, \n",
      "Iter1300, loss:3.7653, \n",
      "          AccB:84.7737, Acc:84.7737, F1@0.10:83.8811, F1@0.25:82.7298, F1@0.50:73.1903, \n",
      "Iter1400, loss:3.6279, \n",
      "          AccB:87.3857, Acc:87.3857, F1@0.10:86.8781, F1@0.25:84.4331, F1@0.50:76.7721, \n",
      "Iter1500, loss:3.6096, \n",
      "          AccB:87.3251, Acc:87.3251, F1@0.10:85.0681, F1@0.25:83.4539, F1@0.50:75.5443, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:75.647, AccB:75.037, Acc:78.694, F1@0.10:79.166, F1@0.25:78.333, F1@0.50:60.000, \n",
      "\n",
      "Iter1600, loss:3.3398, \n",
      "          AccB:89.1445, Acc:89.1445, F1@0.10:88.4765, F1@0.25:86.7038, F1@0.50:79.6127, \n",
      "Iter1700, loss:3.2843, \n",
      "          AccB:88.7589, Acc:88.7589, F1@0.10:87.9803, F1@0.25:85.0957, F1@0.50:79.9675, \n",
      "Iter1800, loss:3.1880, \n",
      "          AccB:90.2534, Acc:90.2534, F1@0.10:89.1695, F1@0.25:88.2208, F1@0.50:83.3197, \n",
      "Iter1900, loss:3.1236, \n",
      "          AccB:90.4700, Acc:90.4700, F1@0.10:88.5869, F1@0.25:87.6292, F1@0.50:82.0426, \n",
      "Iter2000, loss:3.0865, \n",
      "          AccB:91.1718, Acc:91.1718, F1@0.10:88.6909, F1@0.25:87.7216, F1@0.50:82.7136, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:82.586, AccB:77.346, Acc:80.860, F1@0.10:87.301, F1@0.25:82.539, F1@0.50:71.428, \n",
      "\n",
      "✅ Saved Best Model: F1@0.50 = 71.4281\n",
      "   ➤ .net format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.net\n",
      "   ➤ .pth format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.pth\n",
      "Iter2100, loss:2.9846, \n",
      "          AccB:90.2707, Acc:90.2707, F1@0.10:89.0122, F1@0.25:87.5791, F1@0.50:81.2097, \n",
      "Iter2200, loss:2.9164, \n",
      "          AccB:91.9125, Acc:91.9125, F1@0.10:89.5279, F1@0.25:88.8884, F1@0.50:84.0922, \n",
      "Iter2300, loss:2.9685, \n",
      "          AccB:91.1588, Acc:91.1588, F1@0.10:90.6195, F1@0.25:89.9836, F1@0.50:84.7372, \n",
      "Iter2400, loss:2.9278, \n",
      "          AccB:90.7862, Acc:90.7862, F1@0.10:88.8884, F1@0.25:88.5686, F1@0.50:84.0922, \n",
      "Iter2500, loss:2.8011, \n",
      "          AccB:92.3933, Acc:92.3933, F1@0.10:90.9519, F1@0.25:89.6820, F1@0.50:85.7138, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:84.244, AccB:76.486, Acc:82.404, F1@0.10:86.399, F1@0.25:81.599, F1@0.50:67.999, \n",
      "\n",
      "Iter2600, loss:2.8292, \n",
      "          AccB:91.4880, Acc:91.4880, F1@0.10:90.4757, F1@0.25:89.2059, F1@0.50:85.3963, \n",
      "Iter2700, loss:2.7545, \n",
      "          AccB:92.3890, Acc:92.3890, F1@0.10:91.0384, F1@0.25:89.9281, F1@0.50:85.0114, \n",
      "Iter2800, loss:2.6604, \n",
      "          AccB:92.6749, Acc:92.6749, F1@0.10:92.0058, F1@0.25:91.5356, F1@0.50:87.9305, \n",
      "Iter2900, loss:2.6774, \n",
      "          AccB:92.7485, Acc:92.7485, F1@0.10:90.8942, F1@0.25:90.4191, F1@0.50:87.0937, \n",
      "Iter3000, loss:2.5957, \n",
      "          AccB:93.4763, Acc:93.4763, F1@0.10:92.2226, F1@0.25:92.0655, F1@0.50:88.7662, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:84.959, AccB:74.717, Acc:80.223, F1@0.10:85.258, F1@0.25:80.478, F1@0.50:70.916, \n",
      "\n",
      "Iter3100, loss:2.6235, \n",
      "          AccB:93.1947, Acc:93.1947, F1@0.10:92.1255, F1@0.25:91.4956, F1@0.50:88.5034, \n",
      "Iter3200, loss:2.5669, \n",
      "          AccB:93.3680, Acc:93.3680, F1@0.10:93.0409, F1@0.25:92.5718, F1@0.50:87.8807, \n",
      "Iter3300, loss:2.6211, \n",
      "          AccB:92.7399, Acc:92.7399, F1@0.10:92.1502, F1@0.25:90.7373, F1@0.50:86.1847, \n",
      "Iter3400, loss:2.5628, \n",
      "          AccB:93.0388, Acc:93.0388, F1@0.10:91.8234, F1@0.25:90.8800, F1@0.50:88.0498, \n",
      "Iter3500, loss:2.4925, \n",
      "          AccB:93.7752, Acc:93.7752, F1@0.10:92.9178, F1@0.25:92.6065, F1@0.50:88.7155, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:80.528, AccB:76.830, Acc:80.223, F1@0.10:83.333, F1@0.25:79.365, F1@0.50:70.634, \n",
      "\n",
      "Iter3600, loss:2.4538, \n",
      "          AccB:93.5326, Acc:93.5326, F1@0.10:92.7282, F1@0.25:92.4155, F1@0.50:90.0699, \n",
      "Iter3700, loss:2.4563, \n",
      "          AccB:93.8185, Acc:93.8185, F1@0.10:92.9792, F1@0.25:91.8872, F1@0.50:89.8591, \n",
      "Iter3800, loss:2.4695, \n",
      "          AccB:93.9744, Acc:93.9744, F1@0.10:92.5718, F1@0.25:92.1027, F1@0.50:89.4444, \n",
      "Iter3900, loss:2.4794, \n",
      "          AccB:93.8618, Acc:93.8618, F1@0.10:92.4036, F1@0.25:91.9337, F1@0.50:88.6448, \n",
      "Iter4000, loss:2.4107, \n",
      "          AccB:94.4466, Acc:94.4466, F1@0.10:93.8707, F1@0.25:92.9398, F1@0.50:90.1469, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:83.142, AccB:76.523, Acc:81.067, F1@0.10:86.507, F1@0.25:82.539, F1@0.50:69.841, \n",
      "\n",
      "Iter4100, loss:2.4222, \n",
      "          AccB:93.5326, Acc:93.5326, F1@0.10:93.1245, F1@0.25:92.4995, F1@0.50:90.3120, \n",
      "Iter4200, loss:2.3750, \n",
      "          AccB:94.6329, Acc:94.6329, F1@0.10:94.1810, F1@0.25:93.5604, F1@0.50:91.2330, \n",
      "Iter4300, loss:2.4359, \n",
      "          AccB:94.0611, Acc:94.0611, F1@0.10:92.7054, F1@0.25:92.0779, F1@0.50:89.0975, \n",
      "Iter4400, loss:2.3254, \n",
      "          AccB:94.7022, Acc:94.7022, F1@0.10:93.5101, F1@0.25:93.0409, F1@0.50:90.3826, \n",
      "Iter4500, loss:2.3262, \n",
      "          AccB:94.7065, Acc:94.7065, F1@0.10:93.1352, F1@0.25:92.6672, F1@0.50:89.8591, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:82.092, AccB:76.843, Acc:80.764, F1@0.10:86.381, F1@0.25:82.490, F1@0.50:68.482, \n",
      "\n",
      "Iter4600, loss:2.3179, \n",
      "          AccB:94.8928, Acc:94.8928, F1@0.10:93.4879, F1@0.25:93.3328, F1@0.50:91.1623, \n",
      "Iter4700, loss:2.2952, \n",
      "          AccB:95.0097, Acc:95.0097, F1@0.10:94.3362, F1@0.25:94.1810, F1@0.50:91.8537, \n",
      "Iter4800, loss:2.3114, \n",
      "          AccB:94.5462, Acc:94.5462, F1@0.10:94.1810, F1@0.25:92.9398, F1@0.50:90.4572, \n",
      "Iter4900, loss:2.2977, \n",
      "          AccB:94.6415, Acc:94.6415, F1@0.10:94.3450, F1@0.25:93.4155, F1@0.50:90.3171, \n",
      "Iter5000, loss:2.2051, \n",
      "          AccB:95.5122, Acc:95.5122, F1@0.10:94.4181, F1@0.25:94.1080, F1@0.50:91.7824, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:83.897, AccB:78.182, Acc:83.503, F1@0.10:88.976, F1@0.25:85.039, F1@0.50:72.440, \n",
      "\n",
      "✅ Saved Best Model: F1@0.50 = 72.4404\n",
      "   ➤ .net format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.net\n",
      "   ➤ .pth format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.pth\n",
      "Iter5100, loss:2.2637, \n",
      "          AccB:95.2523, Acc:95.2523, F1@0.10:94.6149, F1@0.25:93.8457, F1@0.50:91.3841, \n",
      "Iter5200, loss:2.2680, \n",
      "          AccB:94.9231, Acc:94.9231, F1@0.10:94.3362, F1@0.25:93.8707, F1@0.50:90.7675, \n",
      "------------------------------------Updated Learning Rate--------------------------------\n",
      "Iter5300, loss:2.2317, \n",
      "          AccB:95.0661, Acc:95.0661, F1@0.10:94.3537, F1@0.25:94.0444, F1@0.50:92.4976, \n",
      "Iter5400, loss:2.1721, \n",
      "          AccB:95.9411, Acc:95.9411, F1@0.10:95.3252, F1@0.25:94.8654, F1@0.50:93.3328, \n",
      "Iter5500, loss:2.1674, \n",
      "          AccB:95.7548, Acc:95.7548, F1@0.10:95.0033, F1@0.25:94.6959, F1@0.50:92.3900, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:82.918, AccB:77.776, Acc:82.182, F1@0.10:86.821, F1@0.25:81.395, F1@0.50:72.868, \n",
      "\n",
      "✅ Saved Best Model: F1@0.50 = 72.8677\n",
      "   ➤ .net format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.net\n",
      "   ➤ .pth format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.pth\n",
      "Iter5600, loss:2.1835, \n",
      "          AccB:95.7202, Acc:95.7202, F1@0.10:94.5983, F1@0.25:93.8267, F1@0.50:92.2835, \n",
      "Iter5700, loss:2.1849, \n",
      "          AccB:95.6639, Acc:95.6639, F1@0.10:95.0915, F1@0.25:94.6314, F1@0.50:92.9443, \n",
      "Iter5800, loss:2.1567, \n",
      "          AccB:95.7462, Acc:95.7462, F1@0.10:94.8496, F1@0.25:94.6959, F1@0.50:92.0825, \n",
      "Iter5900, loss:2.1686, \n",
      "          AccB:95.6379, Acc:95.6379, F1@0.10:94.6631, F1@0.25:93.8897, F1@0.50:91.8789, \n",
      "Iter6000, loss:2.1525, \n",
      "          AccB:95.9021, Acc:95.9021, F1@0.10:94.7526, F1@0.25:94.4439, F1@0.50:91.8205, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:85.531, AccB:78.747, Acc:83.933, F1@0.10:89.147, F1@0.25:84.496, F1@0.50:74.418, \n",
      "\n",
      "✅ Saved Best Model: F1@0.50 = 74.4181\n",
      "   ➤ .net format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.net\n",
      "   ➤ .pth format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.pth\n",
      "Iter6100, loss:2.1619, \n",
      "          AccB:95.8588, Acc:95.8588, F1@0.10:94.8337, F1@0.25:94.8337, F1@0.50:93.2917, \n",
      "Iter6200, loss:2.1570, \n",
      "          AccB:95.8025, Acc:95.8025, F1@0.10:95.2303, F1@0.25:94.9226, F1@0.50:92.6149, \n",
      "Iter6300, loss:2.1223, \n",
      "          AccB:96.0624, Acc:96.0624, F1@0.10:94.6959, F1@0.25:94.5422, F1@0.50:93.1586, \n",
      "Iter6400, loss:2.1561, \n",
      "          AccB:95.7721, Acc:95.7721, F1@0.10:95.1571, F1@0.25:94.6959, F1@0.50:92.5437, \n",
      "Iter6500, loss:2.1581, \n",
      "          AccB:95.8674, Acc:95.8674, F1@0.10:95.2376, F1@0.25:94.9304, F1@0.50:93.0871, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:85.264, AccB:77.838, Acc:83.583, F1@0.10:88.030, F1@0.25:83.397, F1@0.50:74.131, \n",
      "\n",
      "Iter6600, loss:2.1345, \n",
      "          AccB:96.1490, Acc:96.1490, F1@0.10:95.4784, F1@0.25:95.1719, F1@0.50:93.9459, \n",
      "Iter6700, loss:2.1507, \n",
      "          AccB:95.9541, Acc:95.9541, F1@0.10:94.4439, F1@0.25:93.8267, F1@0.50:92.4378, \n",
      "Iter6800, loss:2.1434, \n",
      "          AccB:95.8285, Acc:95.8285, F1@0.10:94.2808, F1@0.25:94.1262, F1@0.50:93.1989, \n",
      "Iter6900, loss:2.1640, \n",
      "          AccB:95.5339, Acc:95.5339, F1@0.10:95.0840, F1@0.25:94.4695, F1@0.50:92.9334, \n",
      "Iter7000, loss:2.1458, \n",
      "          AccB:95.7202, Acc:95.7202, F1@0.10:94.1720, F1@0.25:94.0166, F1@0.50:91.9964, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:85.058, AccB:77.936, Acc:82.978, F1@0.10:86.821, F1@0.25:82.945, F1@0.50:72.868, \n",
      "\n",
      "Iter7100, loss:2.1544, \n",
      "          AccB:95.7808, Acc:95.7808, F1@0.10:94.5505, F1@0.25:94.5505, F1@0.50:92.4016, \n",
      "Iter7200, loss:2.1186, \n",
      "          AccB:96.0407, Acc:96.0407, F1@0.10:95.2449, F1@0.25:95.0915, F1@0.50:93.5578, \n",
      "Iter7300, loss:2.1378, \n",
      "          AccB:95.8978, Acc:95.8978, F1@0.10:94.7607, F1@0.25:94.2984, F1@0.50:92.2953, \n",
      "Iter7400, loss:2.1404, \n",
      "          AccB:96.0797, Acc:96.0797, F1@0.10:94.7607, F1@0.25:94.6066, F1@0.50:93.0658, \n",
      "Iter7500, loss:2.1285, \n",
      "          AccB:96.2183, Acc:96.2183, F1@0.10:95.6384, F1@0.25:95.1793, F1@0.50:93.9551, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:86.589, AccB:78.047, Acc:83.885, F1@0.10:89.922, F1@0.25:83.720, F1@0.50:75.193, \n",
      "\n",
      "✅ Saved Best Model: F1@0.50 = 75.1933\n",
      "   ➤ .net format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.net\n",
      "   ➤ .pth format at: /home/cair/Dharmendra/FACT_actseg/src/log/gtea/split2/gtea/1/ckpts/best_model.pth\n",
      "Iter7600, loss:2.1398, \n",
      "          AccB:95.8458, Acc:95.8458, F1@0.10:94.5253, F1@0.25:93.9085, F1@0.50:91.2871, \n",
      "Iter7700, loss:2.1427, \n",
      "          AccB:95.7072, Acc:95.7072, F1@0.10:94.6713, F1@0.25:93.8991, F1@0.50:91.7370, \n",
      "Iter7800, loss:2.1538, \n",
      "          AccB:95.8545, Acc:95.8545, F1@0.10:94.2719, F1@0.25:94.1171, F1@0.50:92.4144, \n",
      "Iter7900, loss:2.0939, \n",
      "          AccB:96.2183, Acc:96.2183, F1@0.10:94.7445, F1@0.25:94.4354, F1@0.50:92.8898, \n",
      "Iter8000, loss:2.1096, \n",
      "          AccB:96.1793, Acc:96.1793, F1@0.10:95.3180, F1@0.25:94.7040, F1@0.50:93.0156, \n",
      "TESTING~~~~~~~~~~\n",
      "Edit:86.462, AccB:77.629, Acc:84.315, F1@0.10:87.937, F1@0.25:82.490, F1@0.50:73.929, \n",
      "\n",
      "Iter8100, loss:2.1408, \n",
      "          AccB:95.6422, Acc:95.6422, F1@0.10:94.7687, F1@0.25:94.6149, F1@0.50:92.3072, \n",
      "Iter8200, loss:2.1538, \n",
      "          AccB:95.9931, Acc:95.9931, F1@0.10:95.4263, F1@0.25:94.6641, F1@0.50:92.6824, \n",
      "Iter8300, loss:2.1270, \n",
      "          AccB:96.0537, Acc:96.0537, F1@0.10:94.9304, F1@0.25:94.6232, F1@0.50:93.2407, \n",
      "Iter8400, loss:2.1274, \n",
      "          AccB:96.2227, Acc:96.2227, F1@0.10:95.2449, F1@0.25:95.0915, F1@0.50:93.7112, \n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Training loop\n",
    "\n",
    "global_step = global_step if 'global_step' in locals() else 0\n",
    "start_epoch = global_step // len(trainloader) if len(trainloader) > 0 else 0\n",
    "\n",
    "ckpt = Checkpoint(-1, bg_class=(dataset.bg_class if cfg.eval_bg else []), eval_edit=False)\n",
    "best_ckpt, best_metric = None, 0\n",
    "\n",
    "print(f'Start Training from Epoch {start_epoch}...')\n",
    "\n",
    "for eidx in range(start_epoch, cfg.epoch):\n",
    "    for batch_idx, (vnames, seq_list, train_label_list, eval_label_list) in enumerate(trainloader):\n",
    "\n",
    "        seq_list = [ s.cuda() for s in seq_list ]\n",
    "        train_label_list = [ s.cuda() for s in train_label_list ]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, video_saves = net(seq_list, train_label_list, compute_loss=True)\n",
    "        loss.backward()\n",
    "\n",
    "        if cfg.clip_grad_norm > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), cfg.clip_grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        save_results(ckpt, vnames, eval_label_list, video_saves)\n",
    "\n",
    "        # Print progress info\n",
    "        if (global_step+1) % cfg.aux.print_every == 0:\n",
    "            ckpt.compute_metrics()\n",
    "            ckpt.average_losses()\n",
    "\n",
    "            log_dict = {}\n",
    "            string = f\"Iter{global_step+1}, \"\n",
    "            _L = len(string)\n",
    "\n",
    "            for k, v in ckpt.loss.items():\n",
    "                log_dict[f\"train-loss/{k}\"] = v\n",
    "                string += f\"{k}:{v:.4f}, \"\n",
    "            print(string)\n",
    "\n",
    "            string = \" \" * _L\n",
    "            for k, v in ckpt.metrics.items():\n",
    "                string += f\"{k}:{v:.4f}, \"\n",
    "                log_dict['train-metric/'+k] = v\n",
    "            print(string)\n",
    "\n",
    "            if run is not None:\n",
    "                run.log(log_dict, step=global_step+1)\n",
    "\n",
    "            ckpt = Checkpoint(-1, bg_class=(dataset.bg_class if cfg.eval_bg else []), eval_edit=False)\n",
    "\n",
    "            if global_step != 0 and (global_step+1) % cfg.aux.eval_every == 0:\n",
    "                test_ckpt = evaluate(global_step, net, testloader, run, savedir)\n",
    "                current_metric = test_ckpt.metrics.get('F1@0.50', 0)\n",
    "\n",
    "                if current_metric >= best_metric:\n",
    "                    best_ckpt = test_ckpt\n",
    "                    best_metric = current_metric\n",
    "\n",
    "                    # Save best model in .net format\n",
    "                    best_model_net_path = os.path.join(ckptdir, 'best_model.net')\n",
    "                    net.save_model(best_model_net_path)\n",
    "\n",
    "                    # Save best model in .pth format (PyTorch standard)\n",
    "                    best_model_pth_path = os.path.join(ckptdir, 'best_model.pth')\n",
    "                    torch.save(net.state_dict(), best_model_pth_path)\n",
    "\n",
    "                    print(f\"✅ Saved Best Model: F1@0.50 = {best_metric:.4f}\")\n",
    "                    print(f\"   ➤ .net format at: {best_model_net_path}\")\n",
    "                    print(f\"   ➤ .pth format at: {best_model_pth_path}\")\n",
    "\n",
    "                # Optional: Always save current iteration model as well (for backup)\n",
    "                network_file = os.path.join(ckptdir, f'network.iter-{global_step+1}.net')\n",
    "                net.save_model(network_file)\n",
    "\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    # Learning rate decay\n",
    "    if cfg.lr_decay > 0 and (eidx + 1) % cfg.lr_decay == 0:\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = cfg.lr * 0.1\n",
    "        print('------------------------------------Updated Learning Rate--------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecabbb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Checkpoint at iteration: 7500\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test-metric/Acc</td><td>▁▃▆▇▇▆▆▇▇█▇██▇██</td></tr><tr><td>test-metric/AccB</td><td>▁▅▇█▇▇▇▇▇███████</td></tr><tr><td>test-metric/Edit</td><td>▁▅▅▇▇█▇▇▇▇▇█████</td></tr><tr><td>test-metric/F1@0.10</td><td>▁▄▄▇▇▆▆▇▇█▇█▇▇█▇</td></tr><tr><td>test-metric/F1@0.25</td><td>▁▄▆▇▇▇▆▇▇█▇█▇▇█▇</td></tr><tr><td>test-metric/F1@0.50</td><td>▁▅▅▇▇▇▇▇▇▇██████</td></tr><tr><td>train-loss/loss</td><td>█▇▆▅▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train-metric/Acc</td><td>▁▃▄▅▆▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>train-metric/AccB</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>train-metric/F1@0.10</td><td>▁▅▆▆▇▇▇▇▇▇▇▇██▇█████████████████████████</td></tr><tr><td>train-metric/F1@0.25</td><td>▁▄▄▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>train-metric/F1@0.50</td><td>▁▂▃▄▅▆▇▇▇▇▇▇▇▇██████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test-metric/Acc</td><td>84.31529</td></tr><tr><td>test-metric/AccB</td><td>77.62899</td></tr><tr><td>test-metric/Edit</td><td>86.46198</td></tr><tr><td>test-metric/F1@0.10</td><td>87.93724</td></tr><tr><td>test-metric/F1@0.25</td><td>82.48977</td></tr><tr><td>test-metric/F1@0.50</td><td>73.92946</td></tr><tr><td>train-loss/loss</td><td>2.12744</td></tr><tr><td>train-metric/Acc</td><td>96.22266</td></tr><tr><td>train-metric/AccB</td><td>96.22266</td></tr><tr><td>train-metric/F1@0.10</td><td>95.2449</td></tr><tr><td>train-metric/F1@0.25</td><td>95.09152</td></tr><tr><td>train-metric/F1@0.50</td><td>93.71116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-fog-10</strong> at: <a href='https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT/runs/sfcemhv6' target=\"_blank\">https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT/runs/sfcemhv6</a><br> View project at: <a href='https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT' target=\"_blank\">https://wandb.ai/upadhyayraghav21-indian-institute-of-information-technol/FACT</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>log/gtea/split2/gtea/1/wandb/run-20250716_163344-sfcemhv6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Final evaluation & finish\n",
    "\n",
    "if best_ckpt is not None:\n",
    "    print(f'Best Checkpoint at iteration: {best_ckpt.iteration}')\n",
    "    best_ckpt.eval_edit = True\n",
    "    best_ckpt.compute_metrics()\n",
    "    best_ckpt.save(os.path.join(logdir, 'best_ckpt.gz'))\n",
    "\n",
    "if run is not None:\n",
    "    run.finish()\n",
    "\n",
    "# Mark experiment complete\n",
    "finish_proof_fname = os.path.join(logdir, \"FINISH_PROOF\")\n",
    "open(finish_proof_fname, \"w\").close()\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577de486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomaev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
